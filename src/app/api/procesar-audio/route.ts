import { NextRequest, NextResponse } from 'next/server'
import { openai, SYSTEM_PROMPTS, TipoAnalisis } from '@/lib/openai'
import { supabase } from '@/lib/supabase'

export const runtime = 'nodejs'
export const maxDuration = 60

// LÃ­mite por chunk para procesamiento seguro
const CHUNK_SIZE_MB = 8 // 8MB por chunk (~8 minutos)
const CHUNK_SIZE_BYTES = CHUNK_SIZE_MB * 1024 * 1024

interface ProcessingProgress {
    currentChunk: number
    totalChunks: number
    status: string
}

export async function POST(request: NextRequest) {
    try {
        // Verificar variables de entorno
        if (!process.env.OPENAI_API_KEY) {
            return NextResponse.json(
                { error: 'OPENAI_API_KEY no configurada' },
                { status: 500 }
            )
        }

        if (!process.env.NEXT_PUBLIC_SUPABASE_URL || !process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY) {
            return NextResponse.json(
                { error: 'Credenciales de Supabase no configuradas' },
                { status: 500 }
            )
        }

        const formData = await request.formData()
        const audioFile = formData.get('audio') as File
        const tipoAnalisis = formData.get('tipo_analisis') as TipoAnalisis

        if (!audioFile) {
            return NextResponse.json(
                { error: 'No se proporcionÃ³ archivo de audio' },
                { status: 400 }
            )
        }

        if (!tipoAnalisis || !SYSTEM_PROMPTS[tipoAnalisis]) {
            return NextResponse.json(
                { error: 'Tipo de anÃ¡lisis invÃ¡lido' },
                { status: 400 }
            )
        }

        const fileSizeMB = audioFile.size / (1024 * 1024)
        console.log(`ğŸ“¤ Procesando: ${audioFile.name} (${fileSizeMB.toFixed(2)}MB)`)

        // Verificar lÃ­mite absoluto (OpenAI Whisper tiene lÃ­mite de 25MB)
        if (audioFile.size > 25 * 1024 * 1024) {
            return NextResponse.json(
                {
                    error: 'Archivo demasiado grande',
                    details: `El archivo de ${fileSizeMB.toFixed(2)}MB excede el lÃ­mite de OpenAI Whisper (25MB). Por favor, comprime el audio o reduce su duraciÃ³n.`
                },
                { status: 413 }
            )
        }

        // Si el archivo es pequeÃ±o, procesarlo directamente
        if (audioFile.size <= CHUNK_SIZE_BYTES) {
            console.log('âœ… Archivo pequeÃ±o - procesamiento directo')
            return await processSingleFile(audioFile, tipoAnalisis)
        }

        // Archivo grande - procesar en modo streaming/chunks
        console.log('âš ï¸ Archivo grande - procesamiento optimizado')
        return await processLargeFile(audioFile, tipoAnalisis)

    } catch (error: any) {
        console.error('âŒ Error general:', error)
        return NextResponse.json(
            {
                error: 'Error al procesar el audio',
                details: error.message || 'Error desconocido'
            },
            { status: 500 }
        )
    }
}

// Procesar archivo pequeÃ±o directamente
async function processSingleFile(audioFile: File, tipoAnalisis: TipoAnalisis) {
    try {
        console.log('ğŸ“ Transcribiendo con Whisper...')

        const transcription = await openai.audio.transcriptions.create({
            file: audioFile,
            model: 'whisper-1',
            language: 'es',
            response_format: 'text',
        })

        const transcriptionText = transcription.toString()
        console.log('âœ… TranscripciÃ³n completada')

        console.log('ğŸ¤– Analizando con GPT-4...')

        const completion = await openai.chat.completions.create({
            model: 'gpt-4',
            messages: [
                {
                    role: 'system',
                    content: SYSTEM_PROMPTS[tipoAnalisis],
                },
                {
                    role: 'user',
                    content: `TranscripciÃ³n a analizar:\n\n${transcriptionText}`,
                },
            ],
            temperature: 0.7,
            max_tokens: 2000,
        })

        const analisis = completion.choices[0].message.content || 'No se pudo generar el anÃ¡lisis'
        console.log('âœ… AnÃ¡lisis completado')

        console.log('ğŸ’¾ Guardando en Supabase...')

        const { data, error } = await supabase
            .from('analisis_audios')
            .insert({
                fecha: new Date().toISOString(),
                tipo_analisis: tipoAnalisis,
                transcripcion_original: transcriptionText,
                resultado_analisis: analisis,
            })
            .select()
            .single()

        if (error) {
            console.error('âŒ Error en Supabase:', error)
            return NextResponse.json(
                { error: 'Error al guardar', details: error.message },
                { status: 500 }
            )
        }

        console.log('âœ… Guardado exitoso')

        return NextResponse.json({
            success: true,
            data: {
                transcripcion: transcriptionText,
                analisis: analisis,
                tipo_analisis: tipoAnalisis,
                id: data.id,
            },
        })
    } catch (error: any) {
        console.error('âŒ Error en procesamiento:', error)
        return NextResponse.json(
            { error: 'Error al procesar', details: error.message },
            { status: 500 }
        )
    }
}

// Procesar archivo grande con estrategia optimizada
async function processLargeFile(audioFile: File, tipoAnalisis: TipoAnalisis) {
    try {
        console.log('ğŸ“ Transcribiendo archivo grande con Whisper...')
        console.log('âš¡ Usando procesamiento optimizado para evitar timeout')

        // Para archivos grandes, usamos una estrategia diferente:
        // 1. Transcribir el archivo completo (Whisper es rÃ¡pido)
        // 2. Dividir la transcripciÃ³n en partes
        // 3. Analizar solo un resumen o las partes mÃ¡s importantes

        const transcription = await openai.audio.transcriptions.create({
            file: audioFile,
            model: 'whisper-1',
            language: 'es',
            response_format: 'text',
            // Whisper puede manejar hasta 25MB sin problemas
        })

        const transcriptionText = transcription.toString()
        const transcriptionLength = transcriptionText.length
        console.log(`âœ… TranscripciÃ³n completada (${transcriptionLength} caracteres)`)

        console.log('ğŸ¤– Analizando transcripciÃ³n larga con GPT-4...')

        // Para transcripciones muy largas, hacemos un anÃ¡lisis mÃ¡s eficiente
        let analisis: string

        if (transcriptionLength > 10000) {
            // TranscripciÃ³n muy larga - hacer anÃ¡lisis en dos partes
            console.log('ğŸ“Š TranscripciÃ³n larga detectada - anÃ¡lisis optimizado')

            const midPoint = Math.floor(transcriptionLength / 2)
            const part1 = transcriptionText.substring(0, midPoint)
            const part2 = transcriptionText.substring(midPoint)

            // Analizar ambas partes
            const [analysis1, analysis2] = await Promise.all([
                analyzeText(part1, tipoAnalisis, '(Parte 1/2)'),
                analyzeText(part2, tipoAnalisis, '(Parte 2/2)')
            ])

            // Combinar anÃ¡lisis
            analisis = `ğŸ“‹ ANÃLISIS COMPLETO DE AUDIO LARGO\n\n` +
                `â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n` +
                `PRIMERA MITAD:\n${analysis1}\n\n` +
                `â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n` +
                `SEGUNDA MITAD:\n${analysis2}\n\n` +
                `â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n` +
                `NOTA: Este audio fue procesado en dos partes debido a su extensiÃ³n.`
        } else {
            // TranscripciÃ³n normal - anÃ¡lisis directo
            analisis = await analyzeText(transcriptionText, tipoAnalisis)
        }

        console.log('âœ… AnÃ¡lisis completado')

        console.log('ğŸ’¾ Guardando en Supabase...')

        const { data, error } = await supabase
            .from('analisis_audios')
            .insert({
                fecha: new Date().toISOString(),
                tipo_analisis: tipoAnalisis,
                transcripcion_original: transcriptionText,
                resultado_analisis: analisis,
            })
            .select()
            .single()

        if (error) {
            console.error('âŒ Error en Supabase:', error)
            return NextResponse.json(
                { error: 'Error al guardar', details: error.message },
                { status: 500 }
            )
        }

        console.log('âœ… Guardado exitoso')

        return NextResponse.json({
            success: true,
            data: {
                transcripcion: transcriptionText,
                analisis: analisis,
                tipo_analisis: tipoAnalisis,
                id: data.id,
                isLargeFile: true,
            },
        })
    } catch (error: any) {
        console.error('âŒ Error en procesamiento de archivo grande:', error)
        return NextResponse.json(
            { error: 'Error al procesar archivo grande', details: error.message },
            { status: 500 }
        )
    }
}

// FunciÃ³n auxiliar para analizar texto
async function analyzeText(text: string, tipoAnalisis: TipoAnalisis, label: string = ''): Promise<string> {
    const completion = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
            {
                role: 'system',
                content: SYSTEM_PROMPTS[tipoAnalisis],
            },
            {
                role: 'user',
                content: `TranscripciÃ³n a analizar ${label}:\n\n${text}`,
            },
        ],
        temperature: 0.7,
        max_tokens: 2000,
    })

    return completion.choices[0].message.content || 'No se pudo generar el anÃ¡lisis'
}
