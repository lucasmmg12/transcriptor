import { NextRequest, NextResponse } from 'next/server'
import { openai, SYSTEM_PROMPTS, TipoAnalisis } from '@/lib/openai'
import { supabase } from '@/lib/supabase'

export const runtime = 'nodejs'
export const maxDuration = 300 // 5 minutos

export async function POST(request: NextRequest) {
    try {
        // Verificar variables de entorno cr√≠ticas
        if (!process.env.OPENAI_API_KEY) {
            console.error('‚ùå OPENAI_API_KEY no est√° configurada')
            return NextResponse.json(
                {
                    error: 'Configuraci√≥n incompleta',
                    details: 'La API key de OpenAI no est√° configurada en las variables de entorno. Por favor config√∫rala en Vercel: Settings ‚Üí Environment Variables ‚Üí OPENAI_API_KEY'
                },
                { status: 500 }
            )
        }

        if (!process.env.NEXT_PUBLIC_SUPABASE_URL || !process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY) {
            console.error('‚ùå Variables de Supabase no configuradas')
            return NextResponse.json(
                {
                    error: 'Configuraci√≥n incompleta',
                    details: 'Las credenciales de Supabase no est√°n configuradas. Por favor config√∫ralas en Vercel.'
                },
                { status: 500 }
            )
        }

        const formData = await request.formData()
        const audioFile = formData.get('audio') as File
        const tipoAnalisis = formData.get('tipo_analisis') as TipoAnalisis

        if (!audioFile) {
            return NextResponse.json(
                { error: 'No se proporcion√≥ archivo de audio' },
                { status: 400 }
            )
        }

        if (!tipoAnalisis || !SYSTEM_PROMPTS[tipoAnalisis]) {
            return NextResponse.json(
                { error: 'Tipo de an√°lisis inv√°lido' },
                { status: 400 }
            )
        }

        console.log('üì§ Iniciando transcripci√≥n con Whisper...')
        console.log('Archivo:', audioFile.name, 'Tama√±o:', audioFile.size, 'bytes')

        // Paso 1: Transcribir el audio con Whisper
        let transcription: string
        try {
            const result = await openai.audio.transcriptions.create({
                file: audioFile,
                model: 'whisper-1',
                language: 'es',
                response_format: 'text',
            })
            transcription = result.toString()
            console.log('‚úÖ Transcripci√≥n completada')
        } catch (error: any) {
            console.error('‚ùå Error en Whisper:', error)
            return NextResponse.json(
                {
                    error: 'Error al transcribir el audio',
                    details: error.message || 'Error desconocido en OpenAI Whisper. Verifica que tu API key sea v√°lida y tenga cr√©ditos.'
                },
                { status: 500 }
            )
        }

        console.log('ü§ñ Iniciando an√°lisis con GPT-4...')

        // Paso 2: Analizar la transcripci√≥n con GPT-4
        let analisis: string
        try {
            const completion = await openai.chat.completions.create({
                model: 'gpt-4',
                messages: [
                    {
                        role: 'system',
                        content: SYSTEM_PROMPTS[tipoAnalisis],
                    },
                    {
                        role: 'user',
                        content: `Transcripci√≥n a analizar:\n\n${transcription}`,
                    },
                ],
                temperature: 0.7,
                max_tokens: 2000,
            })

            analisis = completion.choices[0].message.content || 'No se pudo generar el an√°lisis'
            console.log('‚úÖ An√°lisis completado')
        } catch (error: any) {
            console.error('‚ùå Error en GPT-4:', error)
            return NextResponse.json(
                {
                    error: 'Error al analizar el texto',
                    details: error.message || 'Error desconocido en GPT-4'
                },
                { status: 500 }
            )
        }

        console.log('üíæ Guardando en Supabase...')

        // Paso 3: Guardar en Supabase
        try {
            const { data, error } = await supabase
                .from('analisis_audios')
                .insert({
                    fecha: new Date().toISOString(),
                    tipo_analisis: tipoAnalisis,
                    transcripcion_original: transcription,
                    resultado_analisis: analisis,
                })
                .select()
                .single()

            if (error) {
                console.error('‚ùå Error al guardar en Supabase:', error)
                return NextResponse.json(
                    {
                        error: 'Error al guardar en la base de datos',
                        details: error.message + ' - Verifica que la tabla analisis_audios exista en Supabase.'
                    },
                    { status: 500 }
                )
            }

            console.log('‚úÖ Guardado exitosamente en Supabase')

            return NextResponse.json({
                success: true,
                data: {
                    transcripcion: transcription,
                    analisis: analisis,
                    tipo_analisis: tipoAnalisis,
                    id: data.id,
                },
            })
        } catch (error: any) {
            console.error('‚ùå Error en Supabase:', error)
            return NextResponse.json(
                {
                    error: 'Error al guardar en la base de datos',
                    details: error.message
                },
                { status: 500 }
            )
        }
    } catch (error: any) {
        console.error('‚ùå Error general en el procesamiento:', error)
        return NextResponse.json(
            {
                error: 'Error al procesar el audio',
                details: error.message || 'Error desconocido'
            },
            { status: 500 }
        )
    }
}
