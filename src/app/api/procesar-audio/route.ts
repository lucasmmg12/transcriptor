import { NextRequest, NextResponse } from 'next/server'
import { openai, SYSTEM_PROMPTS, TipoAnalisis } from '@/lib/openai'
import { supabase } from '@/lib/supabase'
import { estimateTokens, splitTextIntoChunks } from '@/lib/audio-utils'

export const runtime = 'nodejs'
export const maxDuration = 60

// LÃ­mite de tokens para GPT-4 (dejamos margen para el system prompt y respuesta)
const MAX_TOKENS_PER_REQUEST = 6000

export async function POST(request: NextRequest) {
    try {
        // Verificar variables de entorno
        if (!process.env.OPENAI_API_KEY) {
            return NextResponse.json(
                { error: 'OPENAI_API_KEY no configurada' },
                { status: 500, headers: { 'Content-Type': 'application/json' } }
            )
        }

        if (!process.env.NEXT_PUBLIC_SUPABASE_URL || !process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY) {
            return NextResponse.json(
                { error: 'Credenciales de Supabase no configuradas' },
                { status: 500, headers: { 'Content-Type': 'application/json' } }
            )
        }

        const formData = await request.formData()
        const audioFile = formData.get('audio') as File
        const tipoAnalisis = formData.get('tipo_analisis') as TipoAnalisis

        if (!audioFile) {
            return NextResponse.json(
                { error: 'No se proporcionÃ³ archivo de audio' },
                { status: 400, headers: { 'Content-Type': 'application/json' } }
            )
        }

        if (!tipoAnalisis || !SYSTEM_PROMPTS[tipoAnalisis]) {
            return NextResponse.json(
                { error: 'Tipo de anÃ¡lisis invÃ¡lido' },
                { status: 400, headers: { 'Content-Type': 'application/json' } }
            )
        }

        const fileSizeMB = audioFile.size / (1024 * 1024)
        console.log(`ğŸ“¤ Procesando: ${audioFile.name} (${fileSizeMB.toFixed(2)}MB)`)

        // Verificar lÃ­mite de OpenAI Whisper
        if (audioFile.size > 25 * 1024 * 1024) {
            return NextResponse.json(
                {
                    error: 'Archivo demasiado grande',
                    details: `El archivo de ${fileSizeMB.toFixed(2)}MB excede el lÃ­mite de 25MB de OpenAI Whisper.`
                },
                { status: 413, headers: { 'Content-Type': 'application/json' } }
            )
        }

        // PASO 1: Transcribir con Whisper
        console.log('ğŸ“ Transcribiendo con Whisper...')
        let transcription: string

        try {
            const result = await openai.audio.transcriptions.create({
                file: audioFile,
                model: 'whisper-1',
                language: 'es',
                response_format: 'text',
            })
            transcription = result.toString()
            console.log(`âœ… TranscripciÃ³n completada (${transcription.length} caracteres)`)
        } catch (error: any) {
            console.error('âŒ Error en Whisper:', error)
            return NextResponse.json(
                {
                    error: 'Error al transcribir',
                    details: error.message || 'Error en OpenAI Whisper'
                },
                { status: 500, headers: { 'Content-Type': 'application/json' } }
            )
        }

        // PASO 2: Analizar con GPT-4 (con manejo inteligente de tokens)
        console.log('ğŸ¤– Analizando con GPT-4...')
        const estimatedTokens = estimateTokens(transcription)
        console.log(`ğŸ“Š Tokens estimados: ${estimatedTokens}`)

        let analisis: string

        try {
            if (estimatedTokens <= MAX_TOKENS_PER_REQUEST) {
                // TranscripciÃ³n corta - anÃ¡lisis directo
                console.log('âœ… TranscripciÃ³n dentro del lÃ­mite - anÃ¡lisis directo')
                analisis = await analyzeText(transcription, tipoAnalisis)
            } else {
                // TranscripciÃ³n larga - dividir en chunks
                console.log(`âš ï¸ TranscripciÃ³n larga (${estimatedTokens} tokens) - dividiendo en chunks`)
                const chunks = splitTextIntoChunks(transcription, MAX_TOKENS_PER_REQUEST)
                console.log(`ğŸ“¦ Dividido en ${chunks.length} chunks`)

                // Analizar cada chunk
                const analyses: string[] = []
                for (let i = 0; i < chunks.length; i++) {
                    console.log(`ğŸ“ Analizando chunk ${i + 1}/${chunks.length}...`)
                    const chunkAnalysis = await analyzeText(
                        chunks[i],
                        tipoAnalisis,
                        `Parte ${i + 1} de ${chunks.length}`
                    )
                    analyses.push(chunkAnalysis)
                }

                // Combinar anÃ¡lisis
                analisis = combineAnalyses(analyses, tipoAnalisis, chunks.length)
            }

            console.log('âœ… AnÃ¡lisis completado')
        } catch (error: any) {
            console.error('âŒ Error en GPT-4:', error)

            // Manejar error de tokens especÃ­ficamente
            if (error.message?.includes('maximum context length') || error.message?.includes('tokens')) {
                return NextResponse.json(
                    {
                        error: 'TranscripciÃ³n demasiado larga',
                        details: `La transcripciÃ³n generÃ³ demasiados tokens (${estimatedTokens} estimados). El audio es muy largo o tiene mucho contenido. Intenta con un audio mÃ¡s corto.`
                    },
                    { status: 413, headers: { 'Content-Type': 'application/json' } }
                )
            }

            return NextResponse.json(
                {
                    error: 'Error al analizar',
                    details: error.message || 'Error en GPT-4'
                },
                { status: 500, headers: { 'Content-Type': 'application/json' } }
            )
        }

        // PASO 3: Guardar en Supabase
        console.log('ğŸ’¾ Guardando en Supabase...')

        try {
            const { data, error } = await supabase
                .from('analisis_audios')
                .insert({
                    fecha: new Date().toISOString(),
                    tipo_analisis: tipoAnalisis,
                    transcripcion_original: transcription,
                    resultado_analisis: analisis,
                })
                .select()
                .single()

            if (error) {
                console.error('âŒ Error en Supabase:', error)
                return NextResponse.json(
                    {
                        error: 'Error al guardar',
                        details: error.message
                    },
                    { status: 500, headers: { 'Content-Type': 'application/json' } }
                )
            }

            console.log('âœ… Guardado exitoso')

            return NextResponse.json({
                success: true,
                data: {
                    transcripcion: transcription,
                    analisis: analisis,
                    tipo_analisis: tipoAnalisis,
                    id: data.id,
                    metadata: {
                        estimatedTokens,
                        wasChunked: estimatedTokens > MAX_TOKENS_PER_REQUEST
                    }
                },
            }, { headers: { 'Content-Type': 'application/json' } })

        } catch (error: any) {
            console.error('âŒ Error en Supabase:', error)
            return NextResponse.json(
                {
                    error: 'Error al guardar',
                    details: error.message
                },
                { status: 500, headers: { 'Content-Type': 'application/json' } }
            )
        }

    } catch (error: any) {
        console.error('âŒ Error general:', error)
        return NextResponse.json(
            {
                error: 'Error al procesar el audio',
                details: error.message || 'Error desconocido'
            },
            { status: 500, headers: { 'Content-Type': 'application/json' } }
        )
    }
}

// FunciÃ³n auxiliar para analizar texto
async function analyzeText(text: string, tipoAnalisis: TipoAnalisis, label: string = ''): Promise<string> {
    const userMessage = label
        ? `${label}\n\nTranscripciÃ³n a analizar:\n\n${text}`
        : `TranscripciÃ³n a analizar:\n\n${text}`

    const completion = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
            {
                role: 'system',
                content: SYSTEM_PROMPTS[tipoAnalisis],
            },
            {
                role: 'user',
                content: userMessage,
            },
        ],
        temperature: 0.7,
        max_tokens: 2000,
    })

    return completion.choices[0].message.content || 'No se pudo generar el anÃ¡lisis'
}

// FunciÃ³n para combinar mÃºltiples anÃ¡lisis
function combineAnalyses(analyses: string[], tipoAnalisis: TipoAnalisis, totalChunks: number): string {
    const header = `ğŸ“‹ ANÃLISIS COMPLETO DE AUDIO LARGO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Este audio fue procesado en ${totalChunks} partes debido a su extensiÃ³n.
A continuaciÃ³n se presenta el anÃ¡lisis de cada parte:

`

    const combinedAnalyses = analyses.map((analysis, index) => {
        return `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ PARTE ${index + 1} DE ${totalChunks}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

${analysis}
`
    }).join('\n')

    const footer = `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… ANÃLISIS COMPLETADO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Total de partes analizadas: ${totalChunks}
Tipo de anÃ¡lisis: ${obtenerNombreTipoAnalisis(tipoAnalisis)}
`

    return header + combinedAnalyses + footer
}

function obtenerNombreTipoAnalisis(tipo: string): string {
    const nombres: Record<string, string> = {
        'entrevista-trabajo': 'Entrevista de Trabajo',
        'reunion-cliente': 'ReuniÃ³n con Cliente',
        'resumen-general': 'Resumen General',
    }
    return nombres[tipo] || tipo
}
